from __future__ import annotations
from typing import List, Optional

from webscout.LLM import LLM


class Message(dict):
    """A message is a dictionary with a 'role' key and a 'content' key.

    The 'role' key is a string indicating the role of the message sender,
    such as 'user' or 'assistant'. The 'content' key is a string containing
    the message text.
    """

    def __init__(
        self, role: str, content: str
    ) -> None:
        """Initialize a Message object.

        Arguments:
            role: The role of the message sender (e.g. 'user' or 'assistant').
            content: The message text.
        """
        super().__init__()
        self['role'] = role
        self['content'] = content


def chat(
    model_name: str,
    messages: List[Message],
    llm: LLM,
) -> Optional[str]:
    """Chat with a language model using a set of messages.

    Arguments:
        model_name: The name of the language model to use.
        messages: A list of Message objects representing the dialogue.

    Returns:
        The response generated by the language model, or None if there is no
        response.
    """
    llm = LLM(model=model_name)
    response = llm.chat(messages)
    return response


# Initialize the LLM class with the model name and system message
llm = LLM(model="microsoft/WizardLM-2-8x22B")

# Define the complete set of messages
messages = [
    Message(
        role="system",
        content="I'm the latest J.A.R.V.I.S. AI, designed by Anonymous with capabilities to access systems through various programming languages using modules like webbrowser, pyautogui, time, pyperclip, random, mouse, wikipedia, keyboard, datetime, tkinter, PyQt5, etc."
    ),
    Message(role="user", content="Open Google Chrome."),
    Message(
        role="assistant", content="python\nimport webbrowser\nwebbrowser.open('https://www.google.com')"
    ),
    Message(
        role="system",
        content="Python includes built-in functions you can use. For instance:",
    ),
    Message(
        role="system",
        content="""from Genration_Of_Images import Generate_Images, Show_Image
    IMGS = Generate_Images(prompt="iron man")
    print(IMGS)
    IMGS_TO_SHOW = Show_Image(IMGS)
    IMGS_TO_SHOW.open(0)
    IMGS_TO_SHOW.open(1)
    """,
    ),
    Message(role="user", content="Jarvis, generate a cute cat image using Python."),
    Message(
        role="assistant",
        content="""from Genration_Of_Images import Generate_Images, Show_Image
    IMGS = Generate_Images(prompt="A playful kitten with bright eyes and a fluffy tail.")
    IMGS_TO_SHOW = Show_Image(IMGS)
    IMGS_TO_SHOW.open(0)
    """,
    ),
    Message(role="user", content="Jarvis, show me the next image using Python."),
    Message(role="assistant", content="IMGS_TO_SHOW.open(1)"),
]

while True:
    # Get the user input
    user_input = input("User: ")

    # Add the user's message to the end of the list of messages
    messages.append(Message(role="user", content=user_input))

    # Use the mistral_chat method to get the response
    response = chat("microsoft/WizardLM-2-8x22B", messages, llm)

    # Print the response
    print("AI: ", response if response is not None else "No response.")

